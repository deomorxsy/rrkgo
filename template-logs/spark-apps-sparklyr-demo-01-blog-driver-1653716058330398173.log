+ sed 's/[^=]*=\(.*\)/\1/g'
+ readarray -t SPARK_EXECUTOR_JAVA_OPTS
+ '[' -n '' ']'
+ '[' 3 == 2 ']'
+ '[' 3 == 3 ']'
++ python3 -V
+ pyv3='Python 3.8.8'
+ export PYTHON_VERSION=3.8.8
+ PYTHON_VERSION=3.8.8
+ export PYSPARK_PYTHON=python3
+ PYSPARK_PYTHON=python3
+ export PYSPARK_DRIVER_PYTHON=python3
+ PYSPARK_DRIVER_PYTHON=python3
+ '[' -n '' ']'
+ '[' -z ']'
+ case "$1" in
+ shift 1
+ CMD=("$SPARK_HOME/bin/spark-submit" --conf "spark.driver.bindAddress=$SPARK_DRIVER_BIND_ADDRESS" --deploy-mode client "$@")
+ exec /usr/bin/tini -s -- /opt/spark/bin/spark-submit --conf spark.driver.bindAddress=10.42.0.11 --deploy-mode client --properties-file /opt/spark/conf/spark.properties --class sparklyr.Shell local:///usr/local/lib/R/site-library/sparklyr/java/sparklyr-2.4-2.12.jar 8880 222 --batch /opt/spark/work-dir/R/blog.R
22/05/28 04:26:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/05/28 04:26:01 INFO sparklyr: Session (222) is starting under 127.0.0.1 port 8880
22/05/28 04:26:01 INFO sparklyr: Session (222) found port 8880 is available
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/05/28 04:26:01 INFO SparkContext: Running Spark version 3.0.2
22/05/28 04:26:01 INFO ResourceUtils: ==============================================================
22/05/28 04:26:01 INFO ResourceUtils: Resources for spark.driver:

22/05/28 04:26:01 INFO ResourceUtils: ==============================================================
22/05/28 04:26:01 INFO SparkContext: Submitted application: sparklyr-demo-01-blog
22/05/28 04:26:01 INFO SecurityManager: Changing view acls to: root
22/05/28 04:26:01 INFO SecurityManager: Changing modify acls to: root
22/05/28 04:26:01 INFO SecurityManager: Changing view acls groups to: 
22/05/28 04:26:01 INFO SecurityManager: Changing modify acls groups to: 
22/05/28 04:26:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
22/05/28 04:26:02 INFO Utils: Successfully started service 'sparkDriver' on port 7078.
22/05/28 04:26:02 INFO SparkEnv: Registering MapOutputTracker
22/05/28 04:26:02 INFO SparkEnv: Registering BlockManagerMaster
22/05/28 04:26:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/05/28 04:26:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/05/28 04:26:02 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/05/28 04:26:02 INFO DiskBlockManager: Created local directory at /var/data/spark-5f65c2e1-d785-4cc3-9ba5-c7b4ee4deada/blockmgr-8909964c-236c-4ee8-9a0f-0baa4ca6e4d0
22/05/28 04:26:03 INFO MemoryStore: MemoryStore started with capacity 93.3 MiB
22/05/28 04:26:03 INFO SparkEnv: Registering OutputCommitCoordinator
22/05/28 04:26:03 INFO Utils: Successfully started service 'SparkUI' on port 4045.
22/05/28 04:26:03 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://sparklyr-demo-01-blog-f4cd9e8108cf7953-driver-svc.spark-apps.svc:4045
22/05/28 04:26:03 INFO SparkContext: Added JAR local:///usr/local/lib/R/site-library/sparklyr/java/sparklyr-2.4-2.12.jar at file:/usr/local/lib/R/site-library/sparklyr/java/sparklyr-2.4-2.12.jar with timestamp 1653711961308
22/05/28 04:26:03 WARN SparkContext: The jar local:///usr/local/lib/R/site-library/sparklyr/java/sparklyr-2.4-2.12.jar has been added already. Overwriting of added jars is not supported in the current version.
22/05/28 04:26:04 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
22/05/28 04:26:08 INFO ExecutorPodsAllocator: Going to request 1 executors from Kubernetes.
22/05/28 04:26:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7079.
22/05/28 04:26:08 INFO NettyBlockTransferService: Server created on sparklyr-demo-01-blog-f4cd9e8108cf7953-driver-svc.spark-apps.svc:7079
22/05/28 04:26:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/05/28 04:26:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sparklyr-demo-01-blog-f4cd9e8108cf7953-driver-svc.spark-apps.svc, 7079, None)
22/05/28 04:26:08 INFO BlockManagerMasterEndpoint: Registering block manager sparklyr-demo-01-blog-f4cd9e8108cf7953-driver-svc.spark-apps.svc:7079 with 93.3 MiB RAM, BlockManagerId(driver, sparklyr-demo-01-blog-f4cd9e8108cf7953-driver-svc.spark-apps.svc, 7079, None)
22/05/28 04:26:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sparklyr-demo-01-blog-f4cd9e8108cf7953-driver-svc.spark-apps.svc, 7079, None)
22/05/28 04:26:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sparklyr-demo-01-blog-f4cd9e8108cf7953-driver-svc.spark-apps.svc, 7079, None)
22/05/28 04:26:11 ERROR SparkContext: Error initializing SparkContext.
java.io.FileNotFoundException: File file:/opt/spark/logs does not exist
    at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:666)
    at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:987)
    at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:656)
    at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:454)
    at org.apache.spark.deploy.history.EventLogFileWriter.requireLogBaseDirAsDirectory(EventLogFileWriters.scala:77)
    at org.apache.spark.deploy.history.SingleEventLogFileWriter.start(EventLogFileWriters.scala:221)
    at org.apache.spark.scheduler.EventLoggingListener.start(EventLoggingListener.scala:81)
    at org.apache.spark.SparkContext.<init>(SparkContext.scala:584)
    at org.apache.spark.SparkContext.<init>(SparkContext.scala:125)
    at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2611)
    at sparklyr.Backend.run(backend.scala:284)
    at sparklyr.Backend.init(backend.scala:205)
    at sparklyr.Shell$.main(shell.scala:49)
    at sparklyr.Shell$.main(shell.scala:12)
    at sparklyr.Shell.main(shell.scala)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
    at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928)
    at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
    at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
    at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
    at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)
    at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)
    at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
22/05/28 04:26:11 INFO SparkUI: Stopped Spark web UI at http://sparklyr-demo-01-blog-f4cd9e8108cf7953-driver-svc.spark-apps.svc:4045
22/05/28 04:26:11 INFO KubernetesClusterSchedulerBackend: Shutting down all executors
22/05/28 04:26:11 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down
22/05/28 04:26:11 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed (this is expected if the application is shutting down.)
22/05/28 04:26:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
22/05/28 04:26:11 INFO MemoryStore: MemoryStore cleared
22/05/28 04:26:11 INFO BlockManager: BlockManager stopped
22/05/28 04:26:11 INFO BlockManagerMaster: BlockManagerMaster stopped
22/05/28 04:26:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
22/05/28 04:26:11 INFO SparkContext: Successfully stopped SparkContext
(22/05/28 04:26:11 ERROR sparklyr: Gateway (222) is shutting down from run() with exception ,java.io.FileNotFoundException: File file:/opt/spark/logs does not exist)
22/05/28 04:26:11 INFO ShutdownHookManager: Shutdown hook called
22/05/28 04:26:11 INFO ShutdownHookManager: Deleting directory /tmp/spark-c2ebf4c8-f78b-48fe-85fe-4586583294ed
22/05/28 04:26:11 INFO ShutdownHookManager: Deleting directory /var/data/spark-5f65c2e1-d785-4cc3-9ba5-c7b4ee4deada/spark-a467a090-a0bc-466f-8935-895a0a86e96a
Stream closed EOF for spark-apps/sparklyr-demo-01-blog-driver (spark-kubernetes-driver)
