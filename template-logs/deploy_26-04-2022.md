```
2022-04-26T15:42:32.382816420-03:00     at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:879)
2022-04-26T15:42:32.382818494-03:00     at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:341)
2022-04-26T15:42:32.382820578-03:00     at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:84)
2022-04-26T15:42:32.382822612-03:00     at org.apache.spark.deploy.k8s.submit.Client.run(KubernetesClientApplication.scala:139)
2022-04-26T15:42:32.382824796-03:00     at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$3(KubernetesClientApplication.scala:213)
2022-04-26T15:42:32.382826880-03:00     at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$3$adapted(KubernetesClientApplication.scala:207)
2022-04-26T15:42:32.382828974-03:00     at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2611)
2022-04-26T15:42:32.382831027-03:00     at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.run(KubernetesClientApplication.scala:207)
2022-04-26T15:42:32.382833101-03:00     at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.start(KubernetesClientApplication.scala:179)
2022-04-26T15:42:32.382835165-03:00     at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)
2022-04-26T15:42:32.382837229-03:00     at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
2022-04-26T15:42:32.382839263-03:00     at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
2022-04-26T15:42:32.382841347-03:00     at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
2022-04-26T15:42:32.382843391-03:00     at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1030)
2022-04-26T15:42:32.382845444-03:00     at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1039)
2022-04-26T15:42:32.382850233-03:00     at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2022-04-26T15:42:32.382855483-03:00 22/04/26 18:42:32 INFO ShutdownHookManager: Shutdown hook called
2022-04-26T15:42:32.382857697-03:00 22/04/26 18:42:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc3f292e-2a8d-4bfc-a807-40b2733e03d5
2022-04-26T15:42:32.383106634-03:00 I0426 18:42:32.383050      10 controller.go:826] Update the status of SparkApplication spark-apps/template-sparklyr-pi-00 from:
2022-04-26T15:42:32.383111804-03:00 {
2022-04-26T15:42:32.383114699-03:00   "lastSubmissionAttemptTime": null,
2022-04-26T15:42:32.383117274-03:00   "terminationTime": null,
2022-04-26T15:42:32.383119939-03:00   "driverInfo": {},
2022-04-26T15:42:32.383122063-03:00   "applicationState": {
2022-04-26T15:42:32.383124297-03:00     "state": ""
2022-04-26T15:42:32.383126431-03:00   }
2022-04-26T15:42:32.383128545-03:00 }
2022-04-26T15:42:32.383130649-03:00 to:
2022-04-26T15:42:32.383132763-03:00 {
2022-04-26T15:42:32.383134987-03:00   "lastSubmissionAttemptTime": "2022-04-26T18:42:32Z",
2022-04-26T15:42:32.383137081-03:00   "terminationTime": null,
2022-04-26T15:42:32.383139165-03:00   "driverInfo": {},
2022-04-26T15:42:32.383141229-03:00   "applicationState": {
2022-04-26T15:42:32.383143313-03:00     "state": "SUBMISSION_FAILED",
2022-04-26T15:42:32.383147932-03:00     "errorMessage": "failed to run spark-submit for SparkApplication spark-apps/template-sparklyr-pi-00: WARNING: An illegal reflective access operation has occurred\nWARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\n22/04/26 18:42:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n22/04/26 18:42:31 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file\n22/04/26 18:42:31 INFO KerberosConfDriverFeatureStep: You have not specified a krb5.conf file locally or via a ConfigMap. Make sure that you have the krb5.conf locally on the driver image.\nException in thread \"main\" io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.43.0.1/api/v1/namespaces/spark-apps/pods. Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. pods \"template-sparklyr-pi-00-driver\" is forbidden: exceeded quota: compute-resources, requested: requests.memory=896Mi, used: requests.memory=0, limited: requests.memory=512m.\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:589)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:526)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:492)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:451)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:252)\n\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:879)\n\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:341)\n\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:84)\n\tat org.apache.spark.deploy.k8s.submit.Client.run(KubernetesClientApplication.scala:139)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$3(KubernetesClientApplication.scala:213)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$3$adapted(KubernetesClientApplication.scala:207)\n\tat org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2611)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.run(KubernetesClientApplication.scala:207)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.start(KubernetesClientApplication.scala:179)\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1030)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1039)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n22/04/26 18:42:32 INFO ShutdownHookManager: Shutdown hook called\n22/04/26 18:42:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc3f292e-2a8d-4bfc-a807-40b2733e03d5\n"
2022-04-26T15:42:32.383172368-03:00   },
2022-04-26T15:42:32.383175604-03:00   "submissionAttempts": 1
2022-04-26T15:42:32.383177898-03:00 }
2022-04-26T15:42:32.409646680-03:00 I0426 18:42:32.409543      10 controller.go:274] Ending processing key: "spark-apps/template-sparklyr-pi-00"
2022-04-26T15:42:32.412624565-03:00 I0426 18:42:32.412569      10 controller.go:227] SparkApplication spark-apps/template-sparklyr-pi-00 was updated, enqueuing it
2022-04-26T15:42:32.412650414-03:00 I0426 18:42:32.412623      10 controller.go:267] Starting processing key: "spark-apps/template-sparklyr-pi-00"
2022-04-26T15:42:32.412864215-03:00 I0426 18:42:32.412786      10 event.go:282] Event(v1.ObjectReference{Kind:"SparkApplication", Namespace:"spark-apps", Name:"template-sparklyr-pi-00", UID:"25c762b6-3598-4a60-8bfa-74e4398342bd", APIVersion:"sparkoperator.k8s.io/v1beta2", ResourceVersion:"34605", FieldPath:""}): type: 'Warning' reason: 'SparkApplicationFailed' SparkApplication template-sparklyr-pi-00 failed: failed to run spark-submit for SparkApplication spark-apps/template-sparklyr-pi-00: WARNING: An illegal reflective access operation has occurred
2022-04-26T15:42:32.412871839-03:00 WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022-04-26T15:42:32.412876969-03:00 WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022-04-26T15:42:32.412880155-03:00 WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022-04-26T15:42:32.412883281-03:00 WARNING: All illegal access operations will be denied in a future release
2022-04-26T15:42:32.412886387-03:00 22/04/26 18:42:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-04-26T15:42:32.412889212-03:00 Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022-04-26T15:42:32.412891947-03:00 22/04/26 18:42:31 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
2022-04-26T15:42:32.412895153-03:00 22/04/26 18:42:31 INFO KerberosConfDriverFeatureStep: You have not specified a krb5.conf file locally or via a ConfigMap. Make sure that you have the krb5.conf locally on the driver image.
2022-04-26T15:42:32.412898038-03:00 Exception in thread "main" io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.43.0.1/api/v1/namespaces/spark-apps/pods. Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. pods "template-sparklyr-pi-00-driver" is forbidden: exceeded quota: compute-resources, requested: requests.memory=896Mi, used: requests.memory=0, limited: requests.memory=512m.
2022-04-26T15:42:32.412911904-03:00     at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:589)
2022-04-26T15:42:32.412918096-03:00     at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:526)
2022-04-26T15:42:32.412920831-03:00     at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:492)
2022-04-26T15:42:32.412923065-03:00     at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:451)
2022-04-26T15:42:32.412925360-03:00     at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:252)
2022-04-26T15:42:32.412927674-03:00     at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:879)
2022-04-26T15:42:32.412929978-03:00     at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:341)
2022-04-26T15:42:32.412932383-03:00     at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:84)
2022-04-26T15:42:32.412934627-03:00     at org.apache.spark.deploy.k8s.submit.Client.run(KubernetesClientApplication.scala:139)
2022-04-26T15:42:32.412937132-03:00     at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$3(KubernetesClientApplication.scala:213)
2022-04-26T15:42:32.412939446-03:00     at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$3$adapted(KubernetesClientApplication.scala:207)
2022-04-26T15:42:32.412941660-03:00     at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2611)
2022-04-26T15:42:32.412946930-03:00     at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.run(KubernetesClientApplication.scala:207)
2022-04-26T15:42:32.412949385-03:00     at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.start(KubernetesClientApplication.scala:179)
2022-04-26T15:42:32.412951669-03:00     at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)
2022-04-26T15:42:32.412953943-03:00     at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
2022-04-26T15:42:32.412956207-03:00     at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
2022-04-26T15:42:32.412958532-03:00     at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
2022-04-26T15:42:32.412961187-03:00     at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1030)
2022-04-26T15:42:32.412964072-03:00     at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1039)
2022-04-26T15:42:32.412967018-03:00     at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2022-04-26T15:42:32.412969603-03:00 22/04/26 18:42:32 INFO ShutdownHookManager: Shutdown hook called
2022-04-26T15:42:32.412972207-03:00 22/04/26 18:42:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc3f292e-2a8d-4bfc-a807-40b2733e03d5
2022-04-26T15:42:32.413723386-03:00 I0426 18:42:32.413566      10 controller.go:826] Update the status of SparkApplication spark-apps/template-sparklyr-pi-00 from:
2022-04-26T15:42:32.413748273-03:00 {
2022-04-26T15:42:32.413765485-03:00   "lastSubmissionAttemptTime": "2022-04-26T18:42:32Z",
2022-04-26T15:42:32.413775193-03:00   "terminationTime": null,
2022-04-26T15:42:32.413783319-03:00   "driverInfo": {},
2022-04-26T15:42:32.413790542-03:00   "applicationState": {
2022-04-26T15:42:32.413797736-03:00     "state": "SUBMISSION_FAILED",
2022-04-26T15:42:32.413812213-03:00     "errorMessage": "failed to run spark-submit for SparkApplication spark-apps/template-sparklyr-pi-00: WARNING: An illegal reflective access operation has occurred\nWARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\n22/04/26 18:42:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n22/04/26 18:42:31 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file\n22/04/26 18:42:31 INFO KerberosConfDriverFeatureStep: You have not specified a krb5.conf file locally or via a ConfigMap. Make sure that you have the krb5.conf locally on the driver image.\nException in thread \"main\" io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.43.0.1/api/v1/namespaces/spark-apps/pods. Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. pods \"template-sparklyr-pi-00-driver\" is forbidden: exceeded quota: compute-resources, requested: requests.memory=896Mi, used: requests.memory=0, limited: requests.memory=512m.\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:589)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:526)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:492)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:451)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:252)\n\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:879)\n\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:341)\n\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:84)\n\tat org.apache.spark.deploy.k8s.submit.Client.run(KubernetesClientApplication.scala:139)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$3(KubernetesClientApplication.scala:213)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$3$adapted(KubernetesClientApplication.scala:207)\n\tat org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2611)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.run(KubernetesClientApplication.scala:207)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.start(KubernetesClientApplication.scala:179)\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1030)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1039)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n22/04/26 18:42:32 INFO ShutdownHookManager: Shutdown hook called\n22/04/26 18:42:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc3f292e-2a8d-4bfc-a807-40b2733e03d5\n"
2022-04-26T15:42:32.413836248-03:00   },
2022-04-26T15:42:32.413843772-03:00   "submissionAttempts": 1
2022-04-26T15:42:32.413858139-03:00 }
2022-04-26T15:42:32.413865152-03:00 to:
2022-04-26T15:42:32.413871905-03:00 {
2022-04-26T15:42:32.413878828-03:00   "lastSubmissionAttemptTime": "2022-04-26T18:42:32Z",
2022-04-26T15:42:32.413885380-03:00   "terminationTime": null,
2022-04-26T15:42:32.413900669-03:00   "driverInfo": {},
2022-04-26T15:42:32.413907762-03:00   "applicationState": {
2022-04-26T15:42:32.413914966-03:00     "state": "FAILED",
2022-04-26T15:42:32.413923101-03:00     "errorMessage": "failed to run spark-submit for SparkApplication spark-apps/template-sparklyr-pi-00: WARNING: An illegal reflective access operation has occurred\nWARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\n22/04/26 18:42:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n22/04/26 18:42:31 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file\n22/04/26 18:42:31 INFO KerberosConfDriverFeatureStep: You have not specified a krb5.conf file locally or via a ConfigMap. Make sure that you have the krb5.conf locally on the driver image.\nException in thread \"main\" io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.43.0.1/api/v1/namespaces/spark-apps/pods. Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. pods \"template-sparklyr-pi-00-driver\" is forbidden: exceeded quota: compute-resources, requested: requests.memory=896Mi, used: requests.memory=0, limited: requests.memory=512m.\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:589)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:526)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:492)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:451)\n\tat io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:252)\n\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:879)\n\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:341)\n\tat io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:84)\n\tat org.apache.spark.deploy.k8s.submit.Client.run(KubernetesClientApplication.scala:139)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$3(KubernetesClientApplication.scala:213)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$3$adapted(KubernetesClientApplication.scala:207)\n\tat org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2611)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.run(KubernetesClientApplication.scala:207)\n\tat org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.start(KubernetesClientApplication.scala:179)\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:951)\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1030)\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1039)\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n22/04/26 18:42:32 INFO ShutdownHookManager: Shutdown hook called\n22/04/26 18:42:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc3f292e-2a8d-4bfc-a807-40b2733e03d5\n"
2022-04-26T15:42:32.413931056-03:00   },
2022-04-26T15:42:32.413938099-03:00   "submissionAttempts": 1
2022-04-26T15:42:32.413954740-03:00 }
2022-04-26T15:42:32.421472379-03:00 I0426 18:42:32.421384      10 controller.go:274] Ending processing key: "spark-apps/template-sparklyr-pi-00"
2022-04-26T15:42:32.423699817-03:00 I0426 18:42:32.423642      10 controller.go:227] SparkApplication spark-apps/template-sparklyr-pi-00 was updated, enqueuing it
2022-04-26T15:42:32.423724012-03:00 I0426 18:42:32.423691      10 controller.go:267] Starting processing key: "spark-apps/template-sparklyr-pi-00"
2022-04-26T15:42:32.423812148-03:00 I0426 18:42:32.423782      10 controller.go:274] Ending processing key: "spark-apps/template-sparklyr-pi-00"
```
